{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Part2_LogisticRegression_pseudo.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO_s7BZnhsGR"
      },
      "source": [
        "# Logistic Regression \n",
        "\n",
        "In this project, I will use gradient ascent to find the weights for the logistic regression.   \n",
        "\n",
        "As an example, I will use the widely-used breast cancer data set. This data set is described here:\n",
        "\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKjC7yi4hsGS"
      },
      "source": [
        "## Step 1:  Getting, preprocessing, and understanding the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqzC5ZKfhsGT"
      },
      "source": [
        "### Importing the standard libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1NVIVdNhsGT"
      },
      "source": [
        "# Importing important libraries\n",
        "# Import breastcancer dataset\n",
        "# Import preprocessing from sklearn\n",
        "# Import train_test_split from sklearn\n",
        "# Import numpy,math\n",
        "\n",
        "%matplotlib inline \n",
        "import sklearn.preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as pltâ€©"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOs3sdOqhsGT"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jf47kYGhsGU"
      },
      "source": [
        "# Load dataset to a python variable cancer\n",
        "# Store target to a variable called y\n",
        "# Store feature to a variable called X\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "print(cancer.keys())\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "print(type(cancer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCC321UfhsGU",
        "outputId": "4ee49679-c2e2-441e-fba9-7cb83309cdca"
      },
      "source": [
        "# Printing the shape of data (X) and target (Y) values \n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVetPgBYhsGU"
      },
      "source": [
        "### Data Pre-Processing\n",
        "#### Splitting the data into train and test before scaling the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcHzQEeBhsGV"
      },
      "source": [
        "# Use train_test_split() function to split the dataset\n",
        "# Store the return value of pervious step to X_train, X_test, y_train, y_test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vypyhBThsGV"
      },
      "source": [
        "#### Scale the data since we will be using gradient ascent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIa0ji5bhsGV"
      },
      "source": [
        "# Find the scaler of the dataset by using preprocessing.StandardScaler().fit()\n",
        "# Using this scale to scale the X_train and X_test using .transform()\n",
        "scaler = sklearn.preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk7cuwtBhsGV",
        "outputId": "5ddd5694-4fb7-4689-80e4-99b696eb00b2"
      },
      "source": [
        "# TODO - Print the shape of x_train and y_train \n",
        "print(X_train.shape) # It should print (426, 30)\n",
        "print(y_train.shape) # It should print (426,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 30)\n",
            "(426,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMsdltFghsGW"
      },
      "source": [
        "#### Adding a column of ones to the  matrices $X_{train}$ and  $X_{test}$\n",
        "After adding a column of ones $X_{train}=\\left[\\begin{matrix}\n",
        "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
        "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
        "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
        "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
        "\\end{matrix}\\right]$\n",
        "\n",
        "Similarly for $X_{test}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttmc_OkwhsGW",
        "outputId": "2a0d0065-8a8d-403c-fa45-df6c479ff92f"
      },
      "source": [
        "# Append a column of ones to x_train \n",
        "# Create a column vector of ones by using np.ones and reshape\n",
        "# Append a column of ones in the beginning of x_train by using np.hstack\n",
        "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "# Now do the same for the test data\n",
        "\n",
        "# We can check that everything worked correctly by:\n",
        "# Printing out the new dimensions\n",
        "print(\"The trainng data has dimensions: \", X_train.shape, \". The testing data has dimensions: \", X_test.shape)\n",
        "# # Looking at the first two rows of X_train to check everything worked as expected\n",
        "print(X_train[0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The trainng data has dimensions:  (426, 31) . The testing data has dimensions:  (143, 31)\n",
            "[[ 1.         -0.47650454  1.06916993 -0.32927472 -0.51000382  1.70745911\n",
            "   2.61802112  1.73129387  0.98172185  0.83559189  3.05774528 -0.3609251\n",
            "   0.66102692 -0.39203921 -0.36008091  0.03339713  2.55009327  1.36157115\n",
            "   0.38967536 -0.29990979  2.51004661 -0.23051777  2.42056437 -0.27821778\n",
            "  -0.28586222  2.39571731  5.05982113  3.88349948  1.63977233  2.51102177\n",
            "   6.93389202]\n",
            " [ 1.         -1.13284528 -0.42993074 -1.11459218 -0.98031335  0.78304908\n",
            "  -0.34361423 -0.87030815 -0.74525945  0.39611437  1.01112495 -0.54829632\n",
            "  -0.01218325 -0.58929408 -0.57257812  0.27911125 -0.63369494 -0.72789319\n",
            "  -0.65232967  0.74399749  0.01591664 -1.06942183 -0.47516488 -1.06412766\n",
            "  -0.91233782  0.40626955 -0.69099607 -0.96816489 -0.88853091  0.30596389\n",
            "   0.2511347 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ubgdeZhsGW"
      },
      "source": [
        "### Understanding the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc9CZ-rGhsGW",
        "outputId": "b3162d89-cd9d-48a2-8072-bed625667bdd"
      },
      "source": [
        "# Printing the names of all the features\n",
        "print(cancer.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5QGeX72hsGX"
      },
      "source": [
        "# You can add your own code here to better understand the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE8UjxqYhsGX"
      },
      "source": [
        "\n",
        " Before writing the gradient ascent code, there are some helpful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dck9N3tYhsGX"
      },
      "source": [
        "\n",
        " \n",
        "### Sigmoid($z$)\n",
        "The first function I will write is sigmoid($z$)\n",
        "\n",
        "sigmoid($z$) takes as input a column vector of real numbers, $z^T = [z_1, z_2, ..., z_{N'}]$, where $N'$ is the number of  examples\n",
        "\n",
        "It should produce as output a column vector $\\left[\\frac{1}{1+e^{-z_1}},\\frac{1}{1+e^{-z_2}},...,\\frac{1}{1+e^{-z_{N'}}}\\right]^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioX0nQtOhsGX"
      },
      "source": [
        "# Write the sigmoid function\n",
        "def sigmoid(z):\n",
        "    sgmd = 1/(1 + np.exp(-z)) \n",
        "    return sgmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lkZSQ6ChsGX"
      },
      "source": [
        "### Initializing ${\\bf w}$\n",
        "For testing the next functions, I will create a coefficient vector, ${\\bf w}$.\n",
        "We will initialize the coeffients to be $0$, i.e. ${\\bf w}^T = [0,0,\\ldots ,0]$ (could have initialized ${\\bf w}$ to any values.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2ojeIbhsGY"
      },
      "source": [
        "# Initialize w using np.zeros()\n",
        "w = np.zeros((X_train.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqoDAU4ChsGY"
      },
      "source": [
        "### Hypothesis, $h({\\bf x})$\n",
        "The next  function to write is our hypothesis function. \n",
        "\n",
        "For example if our design matrix $X$ consists of single example $X=[1,x_1,x_2,\\ldots,x_d]$ and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, it returns $h({\\bf x})=\\frac{1}{1+e^{-\\left({w_{0}\\cdot 1 +w_1\\cdot x_1+\\cdots w_d\\cdot x_d}\\right)}}$\n",
        "\n",
        "If given a  matrix consisting of $N'$ examples \n",
        "$X=\\left[\\begin{matrix}\n",
        "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
        "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
        "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
        "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
        "\\end{matrix}\\right]$\n",
        "and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, the function returns a column vector\n",
        "$[h({\\bf x}^{(1)}),h({\\bf x}^{(2)},\\ldots, h({\\bf x}^{(N')}]^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9kP-8wMhsGY"
      },
      "source": [
        "# Predict the probability that a patient has cancer \n",
        "# Write the hypothesis function \n",
        "def hypothesis(X , w):\n",
        "    return sigmoid(np.dot(X,w))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j79Q8J48hsGY"
      },
      "source": [
        "### Log-Likelihood Function.\n",
        "Write the code to calculate the log likelihood function $\\ell({\\bf w})=\n",
        "\\sum_{i=1}^{N'}y^{(i)}\\ln(h({\\bf x}^{(i)})) +(1- y^{(i)})\\ln(1-h({\\bf x}^{(i)}))$\n",
        "\n",
        "The input is a matrix consisting of $N'$ examples $X=\\left[\\begin{matrix}\n",
        "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
        "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
        "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
        "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
        "\\end{matrix}\\right]$\n",
        "and a column vector ${\\bf y}^T=[y^{(1)},y^{(2)},\\dots,y^{(N')}]$ of labels for $X$.\n",
        "\n",
        "The output is $\\ell({\\bf w})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgyxv_aqhsGZ",
        "outputId": "78aa9bb6-86f5-446d-dbae-0d6ecf9a06ee"
      },
      "source": [
        "# Write the log likelihood function \n",
        "def log_likelihood(X , y , w ):\n",
        "  a = sum(sum(y*np.log(hypothesis(X,w)) + (1 - y)*np.log(1-hypothesis(X,w))))\n",
        "  return a\n",
        "\n",
        "print(log_likelihood(X_train, y_train, w))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-295.2806989185347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWnI-NQ2Floy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igEv5fZMhsGZ"
      },
      "source": [
        "# Gradient Ascent\n",
        "Now writing the code to perform gradient ascent. I will use the update rule from the lecture notes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9IdpFUShsGZ"
      },
      "source": [
        "# TODO - Write the gradient ascent function \n",
        "def Logistic_Regresion_Gradient_Ascent(X, y, learning_rate, num_iters):\n",
        "    # For every 100 iterations, store the log_likelihood for the current w\n",
        "    # Initializing log_likelihood to be an empty list  \n",
        "    # Initialize w to be a zero vector of shape x_train.shape[1],1\n",
        "    # Initialize N to the number of training examples\n",
        "    log_likelihood_values = []\n",
        "    w = np.zeros((X_train.shape[1], 1))\n",
        "    N = X_train.shape[0]\n",
        "    y = y.reshape(y.shape[0],1)\n",
        "    for i in range(num_iters): \n",
        "        # update the w using formula\n",
        "        # append the log_likelihodd values to the list for every 100 iterations\n",
        "        error = y - hypothesis(X, w)\n",
        "        gradient = (1/N) * np.dot(X.T, error)\n",
        "        w += gradient * learning_rate\n",
        "        if i % 100 is 0: \n",
        "          log_likelihood_values.append(log_likelihood(X, y, w))\n",
        "    return w, log_likelihood_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XezJ4kghsGZ"
      },
      "source": [
        "### After completing the code above, run the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbeq-ud0hsGZ",
        "outputId": "0abfc6c2-5b09-4137-be49-58e3d6337f31"
      },
      "source": [
        "# Set the learning_rate\n",
        "# Set the num_iters \n",
        "# Run the Logistic_Regresion_Gradient_Ascent() and store the returned values\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "learning_rate = 0.1\n",
        "num_iters = 2646\n",
        "w, log_likelihood_values = Logistic_Regresion_Gradient_Ascent(X_train, y_train, learning_rate , num_iters)\n",
        "print(w)\n",
        "print(log_likelihood_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 31)\n",
            "(426,)\n",
            "[[ 0.41236259]\n",
            " [-0.35113387]\n",
            " [-0.55621928]\n",
            " [-0.32664897]\n",
            " [-0.43929659]\n",
            " [-0.32226084]\n",
            " [ 0.43738212]\n",
            " [-0.84160684]\n",
            " [-0.91951854]\n",
            " [ 0.25510898]\n",
            " [ 0.31600747]\n",
            " [-1.43741335]\n",
            " [ 0.01992376]\n",
            " [-0.74627901]\n",
            " [-1.13433395]\n",
            " [-0.21941376]\n",
            " [ 0.85974467]\n",
            " [ 0.09319953]\n",
            " [-0.26585219]\n",
            " [ 0.4603329 ]\n",
            " [ 0.60481201]\n",
            " [-1.06579486]\n",
            " [-1.11098512]\n",
            " [-0.80971855]\n",
            " [-1.02767726]\n",
            " [-0.83842663]\n",
            " [-0.05549632]\n",
            " [-0.94969195]\n",
            " [-1.01498284]\n",
            " [-1.03741495]\n",
            " [-0.48023032]]\n",
            "[-0.5228435360323179, -0.10766165228836587, -0.09039698758236035, -0.08281307650994257, -0.07825961056754271, -0.07511051434355874, -0.07274940548270988, -0.07088431081325203, -0.06935638576083991, -0.06807062469585469, -0.06696615006647834, -0.06600185195296883, -0.06514879518475511, -0.06438591473331885, -0.0636974360485484, -0.0630712581734656, -0.06249790244917881, -0.061969807925310934, -0.06148084694372121, -0.06102598466732326, -0.06060103497769499, -0.0602024821581336, -0.05982734823162897, -0.05947309246053116, -0.05913753383958456, -0.05881879028662719, -0.05851523016756624]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbDqweHGhsGa"
      },
      "source": [
        "# Plotting Likelihood v/s Number of Iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "bzpaNG87hsGa",
        "outputId": "80c95f6f-2d1b-43d4-ac04-b15e613d9ef4"
      },
      "source": [
        "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
        "iters = np.array(range(0, num_iters, 100))\n",
        "plt.plot(iters, log_likelihood_values, '.-', color='green')\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Likelihood')\n",
        "plt.title(\"Likelihood vs Number of Iterations.\")\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0d9f12cfd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Number of iterations')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Likelihood')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Likelihood vs Number of Iterations.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XGbEMHlhsGb"
      },
      "source": [
        "#  Evaluating your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQoRZgVFhsGb",
        "outputId": "606b63d3-f1a1-45f7-cd68-d0465fa538ae"
      },
      "source": [
        "# use hypothesis(...) to predict.\n",
        "prediction = hypothesis(X_test, w)\n",
        "print(prediction.shape)\n",
        "prediction = prediction.reshape(prediction.shape[0])\n",
        "print(prediction.shape)\n",
        "threshold = 0.5\n",
        "after_threshold = (prediction >= threshold).astype(int)\n",
        "\n",
        "# print(after_threshold)\n",
        "# y_test = y_test.reshape(y_test.shape[0])\n",
        "# print(np.sum(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(143, 1)\n",
            "(143,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1quHlwIhsGb",
        "outputId": "075b6d9d-bb73-459c-ce10-3014d55a1d7d"
      },
      "source": [
        "# count TP,FP,FN,FP\n",
        "TP,FP,TN,FN = 0,0,0,0\n",
        "\n",
        "for i in range(y_test.shape[0]):\n",
        "  if y_test[i] == 1 and after_threshold[i] == 1:\n",
        "    TP += 1\n",
        "  elif y_test[i] == 0 and after_threshold[i] == 1:\n",
        "    FP += 1\n",
        "  elif y_test[i] == 1 and after_threshold[i] == 0:\n",
        "    FN += 1\n",
        "  elif y_test[i] == 0 and after_threshold[i] == 0:\n",
        "    TN += 1\n",
        "\n",
        "# calculate precision, recall and f1\n",
        "precision = TP/(TP+FP)\n",
        "recall = TP/(TP+FN)\n",
        "fl = 2*(precision*recall) / (precision+recall)\n",
        "\n",
        "print(\"Precision: \",precision)\n",
        "print(\"Recall: \",recall) \n",
        "print(\"F1: \",fl)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(\"TP: \",TP,\" FN: \",FN,\" FP: \",FP,\" TN: \",TN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:  0.9885057471264368\n",
            "Recall:  1.0\n",
            "F1:  0.9942196531791908\n",
            "Confusion Matrix: \n",
            "TP:  86  FN:  0  FP:  1  TN:  56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGG46Yx-7_a8"
      },
      "source": [
        "##########################################\n",
        "################# REPORT #################\n",
        "##########################################\n",
        "\n",
        "# Below is the set of results for all attempted hyperparameters.\n",
        "# The best case result achieved was from the following hyperparameters:\n",
        "# learning_rate = 0.1, num_iters = 2646, threshold = 0.5\n",
        "\n",
        "# ------------- Best result ------------- #\n",
        "# Precision:  0.9885057471264368          #\n",
        "# Recall:  1.0                            #\n",
        "# F1:  0.9942196531791908                 #\n",
        "# Confusion Matrix:                       #\n",
        "# TP:  86  FN:  0  FP:  1  TN:  56        #\n",
        "# --------------------------------------- #\n",
        "\n",
        "\n",
        "# # learning_rate = 0.1 / num_iters = 5000\n",
        "# Precision:  0.9772727272727273\n",
        "# Recall:  1.0\n",
        "# F1:  0.9885057471264368\n",
        "# TP:  86  FN:  0  FP:  2  TN:  55\n",
        "\n",
        "\n",
        "# # learning_rate = 0.1 / num_iters = 2000\n",
        "# Precision:  0.9885057471264368\n",
        "# Recall:  1.0\n",
        "# F1:  0.9942196531791908\n",
        "# Confusion Matrix: \n",
        "# TP:  86  FN:  0  FP:  1  TN:  56\n",
        "\n",
        "\n",
        "# # learning_rate = 0.1 / num_iters = 1000\n",
        "# Precision:  0.9885057471264368\n",
        "# Recall:  1.0\n",
        "# F1:  0.9942196531791908\n",
        "#TP:  86  FN:  0  FP:  1  TN:  56\n",
        "\n",
        "\n",
        "# # learning_rate = 0.5 / num_iters = 5000\n",
        "# Precision:  0.9767441860465116\n",
        "# Recall:  0.9767441860465116\n",
        "# F1:  0.9767441860465116\n",
        "# Confusion Matrix: \n",
        "# TP:  84  FN:  2  FP:  2  TN:  55\n",
        "\n",
        "\n",
        "# # learning_rate = 0.5 / num_iters = 2000\n",
        "# Precision:  0.9767441860465116\n",
        "# Recall:  0.9767441860465116\n",
        "# F1:  0.9767441860465116\n",
        "# Confusion Matrix: \n",
        "# TP:  84  FN:  2  FP:  2  TN:  55\n",
        "\n",
        "\n",
        "# # learning_rate = 0.5 / num_iters = 1000\n",
        "# Precision:  0.9772727272727273\n",
        "# Recall:  1.0\n",
        "# F1:  0.9885057471264368\n",
        "# Confusion Matrix: \n",
        "# TP:  86  FN:  0  FP:  2  TN:  55"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}